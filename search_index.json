[["index.html", "Portfolio 1 Introduction", " Portfolio Rachelle Balgit 1 Introduction Hi, welcome to my Portfolio! My name is Rachelle Balgit, and this portfolio serves as a comprehensive collection of my work and projects in the fields of data analysis and scientific research. As a student in life sciences, I have dedicated myself to exploring and analyzing biological data to uncover insights that are both impact- and meaningful. This portfolio showcases a diverse array of projects and assignments, ranging from academic research endeavors to practical data analysis and visualization tasks. Each project is crafted to highlight my proficiency in data analysis, programming, and problem-solving, demonstrating the skills and expertise I have developed throughout this course. "],["cv.html", "2 CV Education Important Courses Projects Minor Data science for Biology Important Skills", " 2 CV Motivated student persuing degree in biomedical sciences, with a big interest in microbiology and data science. Speaks fluent Dutch and English. Always eager to learn and seeking for new experiences. Always hard working, organized and capable of working in a team or individual. Education Bachelor’s Degree Life Sciences (biomedical sciences), Hogeschool Utrecht (2020-current) • Specializing in microbiology • Minor in Data science for biology part 1 and 2 Important Courses • Medical Microbiological Diagnosis • Laboratory Tools • Research in Microbiology • Immunology • Experimental Design Projects Project Genes &amp; Proteins: Determination of expression of IL-8 with a green fluorescent protein Researching increased IL-8 protein levels of patients with an RSV infection Project Microbiology: Determination of an infection associated with Neisseria gonorrhoeae of patients Using PCR and VITEK Project Research Microbiology: Researching the outer membrane vesicles of Porphyromonas gingivalis of patients with parodontitis Using spectrometry and different isolation methods Minor Data science for Biology Data analysis using R RNA-sequencing Metagenomics Next Generation Sequencing Important Skills • MALDI-TOF • VITEK • (Q)PCR • ELISA • Chromotography • Cultering of bacteria "],["guerilla-analytics.html", "3 Guerilla Analytics", " 3 Guerilla Analytics When working with a lot of data-files, it is essential to keep all these files organized in order to have a structured data analysis workflow framework.To build this kind of framework, I used the Guerrilla Analytics. While using the Guerrilla analytics, I kept the 7 principles of this method in mind: Space is cheap, confusion is expensive Use simple, visual project structures and conventions Automate with program code Link stored data to data in the analytics environment to data in work products Version control changes to data and analytics code (Git/Github.com) Consolidate team knowledge (agree on guidelines and stick to it as a team) Use code that runs from start to finish For the past course, DAUR-II, I created a lot of files. The DAUR-II course let me work on how to analyse two real biological sets of data: RNA-sequencing data and metagenomics data. When organizing my RNA-sequencing data files (Figure 1.), I have first created “README.txt” text files. These README files provide the essential information about a project. For the RNA-sequencing data this included the different types of methods that were used to pre(process) and essential packages to install etc. Following the README.txt we have a folder called “data”. This folder contains all data processing files categorized in subfolders and a special folder for all figures. Figure 1. Folder tree for the RNA-sequencing data For organizing the metagnomics data files (Figure 2.) the same structure has been made for the folder tree as the RNA-sequencing analyses. The only important addition to this tree is the folder for the final versions of my Rmarkdowns. My final version was named under “Meta.Rmd” in the folder “v2”. Figure 2. Folder tree for the metagnomics data "],["reproducible-research.html", "4 Reproducible Research C. elegans experiment Article", " 4 Reproducible Research C. elegans experiment The data for this exercise was kindly supplied by J. Louter (INT/ILC) and was derived from an experiment in which adult C.elegans nematodes were exposed to varying concentrations of different compounds. First we load in the dataset. library(readxl) CE_LIQ_FLOW_062_Tidydata &lt;- read_excel(&quot;~/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;) head(CE_LIQ_FLOW_062_Tidydata) ## # A tibble: 6 × 34 ## plateRow plateColumn vialNr dropCode expType expReplicate expName ## &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 NA NA 1 a experiment 3 CE.LIQ.FLOW.062 ## 2 NA NA 1 b experiment 3 CE.LIQ.FLOW.062 ## 3 NA NA 1 c experiment 3 CE.LIQ.FLOW.062 ## 4 NA NA 1 d experiment 3 CE.LIQ.FLOW.062 ## 5 NA NA 1 e experiment 3 CE.LIQ.FLOW.062 ## 6 NA NA 2 a experiment 3 CE.LIQ.FLOW.062 ## # ℹ 27 more variables: expDate &lt;dttm&gt;, expResearcher &lt;chr&gt;, expTime &lt;dbl&gt;, ## # expUnit &lt;chr&gt;, expVolumeCounted &lt;dbl&gt;, RawData &lt;dbl&gt;, compCASRN &lt;chr&gt;, ## # compName &lt;chr&gt;, compConcentration &lt;chr&gt;, compUnit &lt;chr&gt;, ## # compDelivery &lt;chr&gt;, compVehicle &lt;chr&gt;, elegansStrain &lt;chr&gt;, ## # elegansInput &lt;dbl&gt;, bacterialStrain &lt;chr&gt;, bacterialTreatment &lt;chr&gt;, ## # bacterialOD600 &lt;dbl&gt;, bacterialConcX &lt;dbl&gt;, bacterialVolume &lt;dbl&gt;, ## # bacterialVolUnit &lt;chr&gt;, incubationVial &lt;chr&gt;, incubationVolume &lt;dbl&gt;, … You would expect the columns RawData, compName and compConcentration all to be numeric. These are the colums we are interested in. RawData = the outcome - number of offspring counted as an integer value, after incubation time, compName = the generic name of the compound/chemical compConcentration = the concentration of the compound # inspect the data types of colums RawData, compName and compConcentration class(CE_LIQ_FLOW_062_Tidydata$RawData) ## [1] &quot;numeric&quot; class(CE_LIQ_FLOW_062_Tidydata$compName) ## [1] &quot;character&quot; class(CE_LIQ_FLOW_062_Tidydata$compConcentration) ## [1] &quot;character&quot; But in R the variable compConcentration is not ‘numeric’, it is of the data type ‘character’. # convert column compConcentration from character to numeric # Remove NA and convert to numeric library(dplyr) CE_LIQ_FLOW_062_Tidydata &lt;- CE_LIQ_FLOW_062_Tidydata %&gt;% mutate(compConcentration = as.numeric(compConcentration)) %&gt;% filter(!is.na(compConcentration)) Scatterplot Scatterplot of the data set for the different compounds and the varying concentrations down below: Figuur 3. Scatterplot of different compounds and varying concentrations The positive control for this experiment is ethanol and the negative control is S-medium. Normalizing the data For the dataset CE_LIQ_FLOW_062_Tidydata, the controleNegative condition was normalized so that its average value equals 1. All values are expressed as a fraction of this, which helps standardize the data and facilitates the interpretation and comparison of the effects of different conditions. # Calculate mean value of controlNegative controlNegative &lt;- CE_LIQ_FLOW_062_Tidydata %&gt;% filter(CE_LIQ_FLOW_062_Tidydata$expType == &quot;controlNegative&quot;) controlNegative_mean &lt;- mean(controlNegative$RawData) controlNegative_mean ## [1] 85.9 # Normalize data CE_LIQ_FLOW_062_Tidydata &lt;- CE_LIQ_FLOW_062_Tidydata %&gt;% mutate(normalized = CE_LIQ_FLOW_062_Tidydata$RawData / controlNegative_mean) # Inspect the data types of columns RawData, compName, expType, compConcentration and normalized CE_LIQ_FLOW_062_Tidydata %&gt;% select(RawData, compName, compConcentration, expType, normalized) ## # A tibble: 359 × 5 ## RawData compName compConcentration expType normalized ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 44 2,6-diisopropylnaphthalene 4.99 experiment 0.512 ## 2 37 2,6-diisopropylnaphthalene 4.99 experiment 0.431 ## 3 45 2,6-diisopropylnaphthalene 4.99 experiment 0.524 ## 4 47 2,6-diisopropylnaphthalene 4.99 experiment 0.547 ## 5 41 2,6-diisopropylnaphthalene 4.99 experiment 0.477 ## 6 35 2,6-diisopropylnaphthalene 4.99 experiment 0.407 ## 7 41 2,6-diisopropylnaphthalene 4.99 experiment 0.477 ## 8 36 2,6-diisopropylnaphthalene 4.99 experiment 0.419 ## 9 40 2,6-diisopropylnaphthalene 4.99 experiment 0.466 ## 10 38 2,6-diisopropylnaphthalene 4.99 experiment 0.442 ## # ℹ 349 more rows Figuur 4. Scatterplot of different compounds and varying concentrations normalized with the mean of the negative control Article An, A.Y. et al. (2023) Dynamic gene expression analysis reveals distinct severity phases of immune and cellular dysregulation in COVID-19, bioRxiv. Available at: https://www.biorxiv.org/content/10.1101/2023.11.04.565404v1.full (Accessed: 02 May 2024). Summary Objective To investigate longitudinal changes in gene expression profiles throughout the COVID-19 disease timeline. Methods Three-hundred whole blood samples from 128 adult patients were collected during hospitalization from COVID-19, with up to five samples per patient. Transcriptome sequencing (RNA-Seq), differential gene expression analysis and pathway enrichment was performed. Drug-gene set enrichment analysis was used to identify FDA-approved medications that could inhibit critical genes and proteins at each disease phase. Prognostic gene-expression signatures were generated using machine learning to distinguish 3 disease stages. Results Samples were longitudinally grouped by clinical criteria and gene expression into six disease phases: Mild, Moderate, Severe, Critical, Recovery, and Discharge. Distinct mechanisms with differing trajectories during COVID-19 hospitalization were apparent. Antiviral responses peaked early in COVID-19, while heme metabolism pathways became active much later during disease. Adaptive immune dysfunction, inflammation, and metabolic derangements were most pronounced during phases with higher disease severity, while hemostatic abnormalities were elevated early and persisted throughout the disease course. Drug-gene set enrichment analysis predicted repurposed medications for potential use, including platelet inhibitors in early disease, antidiabetic medications for patients with increased disease severity, and dasatinib throughout the disease course. Disease phases could be categorized using specific gene signatures for prognosis and treatment selection. Disease phases were also highly correlated to previously developed sepsis endotypes, indicating that severity and disease timing were significant contributors to heterogeneity observed in sepsis and COVID-19. Conclusions Higher temporal resolution of longitudinal mechanisms in COVID-19 revealed multiple immune and cellular changes that were activated at different phases of COVID-19. Understanding how a patient’s gene expression profile changes over time can permit more accurate risk stratification of patients and provide time-dependent personalized treatments with repurposed medications. This creates an opportunity for timely intervention before patients transition to a more severe phase, potentially accelerating patients to recovery. Review The article has been evaluated according to the criteria listed in the table below. Transparency Criteria Definition Response Study Purpose A concise statement in the introduction of the article, often in the last paragraph, that establishes the reason the research was conducted. Also called the study objective. yes Data Availability Statement A statement, in an individual section offset from the main body of text, that explains how or if one can access a study’s data. The title of the section may vary, but it must explicitly mention data; it is therefore distinct from a supplementary materials section. yes Data Location Where the article’s data can be accessed, either raw or processed. The datasets generated for this study can be found on GEO: GSE221234 and GSE222253. Code is available upon request (Dr. Robert Hancock, bob{at}hancocklab.com). Study Location Author has stated in the methods section where the study took place or the data’s country/region of origin. yes, Author Review The professionalism of the contact information that the author has provided in the manuscript. yes, with information of the researchers and an e-mail. Ethics Statement A statement within the manuscript indicating any ethical concerns, including the presence of sensitive data. yes Funding Statement A statement within the manuscript indicating whether or not the authors received funding for their research. yes Code Availability Authors have shared access to the most updated code that they used in their study, including code used for analysis. no "],["new-packages.html", "New Packages Visualisation microplate assay plater gganimate 4.1 4.2 qPCR References", " New Packages Visualisation microplate assay For my internship at the HU Lectoraat of Innovative Testing in Life Sciences and Chemistry, I am working with a lot of data obtained from a microplate reader. To visualize this data I have already used a lot of the functions of the ggplot2 package, which I learned in this course. Now I was wondering if there were maybe more packages that would help me analyse these kind of data since I know I will work with similar data in the future. I have already made scripts like this: # Laad de benodigde bibliotheken library(readxl) library(ggplot2) library(gridExtra) library(dplyr) # Data inlezen van soja met caseine-FITC tryp_alb_soy &lt;- read_excel(&quot;20241028_AlbFITC_soja_alg.xlsx&quot;, sheet = &quot;soy_tryp&quot;) pep_pep_alb_soy &lt;- read_excel(&quot;20241028_AlbFITC_soja_alg.xlsx&quot;, sheet = &quot;soy_pep&quot;) pan_pep_alb_soy &lt;- read_excel(&quot;20241028_AlbFITC_soja_alg.xlsx&quot;, sheet = &quot;soy_pan&quot;) pan_pep_alb_soy &lt;- read_excel(&quot;20241028_AlbFITC_soja_alg.xlsx&quot;, sheet = &quot;soy_pep_pan&quot;) # Data inlezen van alg met caseïne-FITC tryp_alb_alg &lt;- read_excel(&quot;20241028_AlbFITC_soja_alg.xlsx&quot;, sheet = &quot;alg_tryp&quot;) pep_pep_alb_alg &lt;- read_excel(&quot;20241028_AlbFITC_soja_alg.xlsx&quot;, sheet = &quot;alg_pep&quot;) pan_pep_alb_alg &lt;- read_excel(&quot;20241028_AlbFITC_soja_alg.xlsx&quot;, sheet = &quot;alg_pan&quot;) pan_pep_alb_alg &lt;- read_excel(&quot;20241028_AlbFITC_soja_alg.xlsx&quot;, sheet = &quot;alg_pep_pan&quot;) # Definieer de levels voor concentratie_peptones op één plek concentratie_levels &lt;- c(&quot;pepsine + pancreatine + DMEM + alb-FITC&quot;, &quot;DMEM + alb-FITC&quot;, &quot;3.125&quot;, &quot;6.25&quot;, &quot;12.5&quot;, &quot;25&quot;, &quot;50&quot;) # Zet de factor levels voor soja datasets for (data in list(tryp_alb_soy, pep_pep_alb_soy, pan_pep_alb_soy)) { data$concentratie_peptones &lt;- factor(data$concentratie_peptones, levels = concentratie_levels) } # Zet de factor levels voor alg datasets for (data in list(tryp_alb_alg, pep_pep_alb_alg, pan_pep_alb_alg)) { data$concentratie_peptones &lt;- factor(data$concentratie_peptones, levels = concentratie_levels) } # Update de stijl voor de controlecondities linetype_values &lt;- c(&quot;trypsine + DMEM + alb-FITC&quot; = &quot;dashed&quot;, &quot;DMEM + alb-FITC&quot; = &quot;dashed&quot;, &quot;pepsine + DMEM + alb-FITC&quot; = &quot;dashed&quot;, &quot;pancreatine + DMEM + alb-FITC&quot; = &quot;dashed&quot;, &quot;pepsine + pancreatine + DMEM + alb-FITC&quot; = &quot;dashed&quot;, &quot;3.125&quot; = &quot;solid&quot;, &quot;6.25&quot; = &quot;solid&quot;, &quot;12.5&quot; = &quot;solid&quot;, &quot;25&quot; = &quot;solid&quot;, &quot;50&quot; = &quot;solid&quot;) common_colors &lt;- c( &quot;trypsine + DMEM + alb-FITC&quot; = &quot;blue&quot;, &quot;DMEM + alb-FITC&quot; = &quot;red&quot;, &quot;pepsine + DMEM + alb-FITC&quot; = &quot;green&quot;, &quot;pancreatine + DMEM + alb-FITC&quot; = &quot;purple&quot;, &quot;pepsine + pancreatine + DMEM + alb-FITC&quot; = &quot;orange&quot;, &quot;3.125&quot; = &quot;cyan4&quot;, &quot;6.25&quot; = &quot;magenta&quot;, &quot;12.5&quot; = &quot;yellow3&quot;, &quot;25&quot; = &quot;brown3&quot;, &quot;50&quot; = &quot;darkblue&quot; ) # Functie om grafieken te genereren plot_function &lt;- function(data, title_text, concentration_label, add_annotation = FALSE, add_pepsine_t = FALSE, add_pancreatine_annotation = FALSE, add_pan_t = FALSE) { p &lt;- ggplot(data, aes(x = as.numeric(incubatietijd_min), y = gemiddelde_extinctie_meting, color = factor(concentratie_peptones), group = factor(concentratie_peptones), linetype = factor(concentratie_peptones))) + geom_line() + geom_point() + scale_y_log10(expand = c(0.1, 0)) + scale_x_continuous(breaks = c(scales::pretty_breaks()(range(as.numeric(data$incubatietijd_min))), 35), expand = c(0.1, 0)) + scale_color_manual(values = common_colors) + scale_linetype_manual(values = linetype_values) + labs(title = title_text, x = &quot;Incubatietijd (minuten)&quot;, y = &quot;Gemiddelde extinctie (log)&quot;, color = concentration_label, linetype = concentration_label) + theme_minimal() + theme(plot.margin = unit(c(1, 1, 1, 1), &quot;cm&quot;)) # Voeg annotaties toe if (add_annotation) { p &lt;- p + geom_vline(xintercept = 50, linetype = &quot;dotted&quot;, color = &quot;grey50&quot;, size = 0.7) + annotate(&quot;text&quot;, x = 50, y = Inf, label = &quot;afbraak door pepsine&quot;, vjust = -1, hjust = 1.1, color = &quot;grey30&quot;, angle = 90, size = 3.5) } if (add_pancreatine_annotation) { p &lt;- p + geom_vline(xintercept = 230, linetype = &quot;dotted&quot;, color = &quot;grey50&quot;, size = 0.7) + annotate(&quot;text&quot;, x = 230, y = Inf, label = &quot;afbraak door pancreatine&quot;, vjust = -1, hjust = 1.1, color = &quot;grey30&quot;, angle = 90, size = 3.5) } if (add_pepsine_t) { p &lt;- p + geom_vline(xintercept = 15, linetype = &quot;dotted&quot;, color = &quot;grey50&quot;, size = 0.7) + annotate(&quot;text&quot;, x = 15, y = Inf, label = &quot;toevoeging van pepsine&quot;, vjust = -1, hjust = 1.1, color = &quot;grey30&quot;, angle = 90, size = 3.5) } if (add_pan_t) { p &lt;- p + geom_vline(xintercept = 60, linetype = &quot;dotted&quot;, color = &quot;grey50&quot;, size = 0.7) + annotate(&quot;text&quot;, x = 60, y = Inf, label = &quot;toevoeging van pancreatine&quot;, vjust = -1, hjust = 1.1, color = &quot;grey30&quot;, angle = 90, size = 3.5) } return(p) } # Plot de grafieken voor soja tryp_alb_plot_soy &lt;- plot_function(tryp_alb_soy, &quot;Gemiddelde gemeten extinctie albumine-FITC \\nover tijd vrijgekomen na eiwitafbraak door trypsine (log)&quot;, &quot;Concentratie soja (mg/ml)&quot;) pep_pep_alb_plot_soy &lt;- plot_function(pep_pep_alb_soy, &quot;Gemiddelde gemeten extinctie albumine-FITC \\nover tijd vrijgekomen na eiwitafbraak door pepsine (log)&quot;, &quot;Concentratie soja (mg/ml)&quot;, add_annotation = TRUE, add_pepsine_t = TRUE) pan_pep_alb_plot_soy &lt;- plot_function(pan_pep_alb_soy, &quot;Gemiddelde gemeten extinctie albumine-FITC \\nover tijd vrijgekomen na eiwitafbraak door pancreatine (log)&quot;, &quot;Concentratie soja (mg/ml)&quot;, add_pancreatine_annotation = TRUE, add_pan_t = TRUE) pan_pep_alb_plot_soy &lt;- plot_function(pan_pep_alb_soy, &quot;Gemiddelde gemeten extinctie albumine-FITC \\nover tijd vrijgekomen na eiwitafbraak door pepsine en pancreatine (log)&quot;, &quot;Concentratie soja (mg/ml)&quot;, add_annotation = TRUE, add_pancreatine_annotation = TRUE, add_pepsine_t = TRUE, add_pan_t = TRUE) # Plot de grafieken voor alg tryp_alb_plot_alg &lt;- plot_function(tryp_alb_alg, &quot;Gemiddelde gemeten extinctie albumine-FITC \\nover tijd vrijgekomen na eiwitafbraak door trypsine (log)&quot;, &quot;Concentratie alg (mg/ml)&quot;) pep_pep_alb_plot_alg &lt;- plot_function(pep_pep_alb_alg, &quot;Gemiddelde gemeten extinctie albumine-FITC \\nover tijd vrijgekomen na eiwitafbraak door pepsine (log)&quot;, &quot;Concentratie alg (mg/ml)&quot;) pan_pep_alb_plot_alg &lt;- plot_function(pan_pep_alb_alg, &quot;Gemiddelde gemeten extinctie albumine-FITC \\nover tijd vrijgekomen na eiwitafbraak door pancreatine (log)&quot;, &quot;Concentratie alg (mg/ml)&quot;) pan_pep_alb_plot_alg &lt;- plot_function(pan_pep_alb_alg, &quot;Gemiddelde gemeten extinctie albumine-FITC \\nover tijd vrijgekomen na eiwitafbraak door pepsine en pancreatine (log)&quot;, &quot;Concentratie alg (mg/ml)&quot;, add_annotation = TRUE, add_pancreatine_annotation = TRUE, add_pepsine_t = TRUE, add_pan_t = TRUE) # Combineer de plots voor pepsine en pancreatine pan_pep &lt;- grid.arrange(pan_pep_alb_plot_alg, pan_pep_alb_plot_soy, ncol = 1) plater When I was looking for more packages I came across plater. It is not exactly a package in which you can visualise your data, but more for organizing it to work in Rstudio with tidyverse. Learning to use the package seemed very useful to me. Plater makes it easier to work with data from experimetns perfomed in plates. The point is to seasmlessly convert plate-shaped date (easy to think about) into tidy date(easy to analyse). This package does this by defining a simple, systematic format for storing information into plate layouts, followed by rearraging the data into a tidy format frame. — To get familiar with the package I came across an example. In this example we have invented to new antibiotics. To examine the working of these two, we filled up a 96-well plate with dilutions of the antibiotics and four types of bacteria. We are measuring the amount of bacteria that got killed. So in each well of the plate we have: Antibiotic A or B Concentration of the drug (100 uM to 0.01 nM and no drug) Bacterial species (E. coli, S. enterocolitis, C. trachomatis, and N. gonorrhoeae) Amount of killed bacteria. First we begin with installing the package. # install.packages(&quot;plater&quot;) library(plater) There is a format file available for this example experiment what looks like this: Figure 5. Plate format example I tried to test it on my own data but I have encoutered a lot of errors. Whenever I made a .csv file and I tried to load it in, it responded with “it seems like you want to work with two plates”. I have tried to resolve it but it took a lot of time so I decided to move on with another package. library(plater) file_path &lt;- system.file(&quot;extdata&quot;, &quot;example-1.csv&quot;, package = &quot;plater&quot;) data &lt;- read_plate( file = file_path, # full path to the .csv file well_ids_column = &quot;Wells&quot;, # name to give column of well IDs (optional) sep = &quot;,&quot; # separator used in the csv file (optional) ) str(data) ## tibble [96 × 5] (S3: tbl_df/tbl/data.frame) ## $ Wells : chr [1:96] &quot;A01&quot; &quot;A02&quot; &quot;A03&quot; &quot;A04&quot; ... ## $ Drug : chr [1:96] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... ## $ Concentration: num [1:96] 1.00e+02 2.00e+01 4.00 8.00e-01 1.60e-01 3.20e-02 6.40e-03 1.28e-03 2.56e-04 5.12e-05 ... ## $ Bacteria : chr [1:96] &quot;E. coli&quot; &quot;E. coli&quot; &quot;E. coli&quot; &quot;E. coli&quot; ... ## $ Killing : num [1:96] 98 95 92 41 17 2 1.5 1.8 1 0.5 ... head(data) ## # A tibble: 6 × 5 ## Wells Drug Concentration Bacteria Killing ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 A01 A 100 E. coli 98 ## 2 A02 A 20 E. coli 95 ## 3 A03 A 4 E. coli 92 ## 4 A04 A 0.8 E. coli 41 ## 5 A05 A 0.16 E. coli 17 ## 6 A06 A 0.032 E. coli 2 # make a dataframe test_data &lt;- data.frame( well = c( &quot;A1&quot;, &quot;A2&quot;, &quot;A3&quot;, &quot;A4&quot;, &quot;A5&quot;, &quot;A6&quot;, &quot;A7&quot;, &quot;A8&quot;, &quot;A9&quot;, &quot;A10&quot;, &quot;A11&quot;, &quot;A12&quot;, &quot;B1&quot;, &quot;B2&quot;, &quot;B3&quot;, &quot;B4&quot;, &quot;B5&quot;, &quot;B6&quot;, &quot;B7&quot;, &quot;B8&quot;, &quot;B9&quot;, &quot;B10&quot;, &quot;B11&quot;, &quot;B12&quot;, &quot;C1&quot;, &quot;C2&quot;, &quot;C3&quot;, &quot;C4&quot;, &quot;C5&quot;, &quot;C6&quot;, &quot;C7&quot;, &quot;C8&quot;, &quot;C9&quot;, &quot;C10&quot;, &quot;C11&quot;, &quot;C12&quot;, &quot;D1&quot;, &quot;D2&quot;, &quot;D3&quot;, &quot;D4&quot;, &quot;D5&quot;, &quot;D6&quot;, &quot;D7&quot;, &quot;D8&quot;, &quot;D9&quot;, &quot;D10&quot;, &quot;D11&quot;, &quot;D12&quot;, &quot;E1&quot;, &quot;E2&quot;, &quot;E3&quot;, &quot;E4&quot;, &quot;E5&quot;, &quot;E6&quot;, &quot;E7&quot;, &quot;E8&quot;, &quot;E9&quot;, &quot;E10&quot;, &quot;E11&quot;, &quot;E12&quot;, &quot;F1&quot;, &quot;F2&quot;, &quot;F3&quot;, &quot;F4&quot;, &quot;F5&quot;, &quot;F6&quot;, &quot;F7&quot;, &quot;F8&quot;, &quot;F9&quot;, &quot;F10&quot;, &quot;F11&quot;, &quot;F12&quot;, &quot;G1&quot;, &quot;G2&quot;, &quot;G3&quot;, &quot;G4&quot;, &quot;G5&quot;, &quot;G6&quot;, &quot;G7&quot;, &quot;G8&quot;, &quot;G9&quot;, &quot;G10&quot;, &quot;G11&quot;, &quot;G12&quot;, &quot;H1&quot;, &quot;H2&quot;, &quot;H3&quot;, &quot;H4&quot;, &quot;H5&quot;, &quot;H6&quot;, &quot;H7&quot;, &quot;H8&quot;, &quot;H9&quot;, &quot;H10&quot;, &quot;H11&quot;, &quot;H12&quot; ), monster = c( &quot;NC&quot;, &quot;NC&quot;, &quot;tryp100&quot;, &quot;tryp100&quot;, &quot;tryp100&quot;, &quot;tryp100&quot;, &quot;tryp100&quot;, &quot;tryp100&quot;, &quot;tryp100&quot;, &quot;tryp100&quot;, &quot;tryp100&quot;, &quot;tryp100&quot;, &quot;dmem&quot;, &quot;dmem&quot;, &quot;tryp50&quot;, &quot;tryp50&quot;, &quot;tryp50&quot;, &quot;tryp50&quot;, &quot;tryp50&quot;, &quot;tryp50&quot;, &quot;tryp50&quot;, &quot;tryp50&quot;, &quot;tryp50&quot;, &quot;tryp50&quot;, &quot;pep&quot;, &quot;pep&quot;, &quot;pept_cas&quot;, &quot;pept_cas&quot;, &quot;pep_pan&quot;, &quot;pep_pan&quot;, &quot;pep_pan&quot;, &quot;pep_pan&quot;, &quot;pep_pan&quot;, &quot;pep_pan&quot;, &quot;pep_pan&quot;, &quot;pep_pan&quot;, &quot;tryp12&quot;, &quot;tryp12&quot;, &quot;pan_cas&quot;, &quot;pan_cas&quot;, &quot;pan&quot;, &quot;pan&quot;, &quot;pan&quot;, &quot;pan&quot;, &quot;pan&quot;, &quot;pan&quot;, &quot;pept_tryp&quot;, &quot;pept_tryp&quot; ), absorbance = c( 0.747, 0.738, 0.762, 0.838, 0.818, 0.785, 0.859, 0.898, 0.880, 0.862, 0.828, 0.842, 0.764, 0.715, 0.746, 0.915, 0.926, 0.935, 0.980, 0.986, 0.954, 1.016, 1.014, 1.062, 0.744, 0.727, 0.726, 0.746, 0.711, 0.717, 0.788, 0.765, 0.804, 0.785, 0.751, 0.817, 0.707, 0.682, 0.726, 0.702, 0.738, 0.715, 0.754, 0.819, 0.742, 0.803, 0.780, 0.829, 0.720, 0.675, 0.823, 0.782, 0.788, 0.749, 0.758, 0.738, 0.842, 0.880, 0.807, 1.052, 0.823, 0.827, 0.791, 0.875, 0.950, 1.006, 0.930, 0.998, 1.354, 1.020, 1.051, 1.099, 0.886, 0.777, 0.691, 0.723, 0.704, 0.731, 0.753, 0.781, 0.727, 0.808, 0.819, 0.835, 3.500, 0.708, 0.648, 0.796, 0.741, 0.770, 0.766, 0.782, 0.774, 0.888, 0.911, 0.966 ) ) # convert to CSV write.csv(test_data, row.names = FALSE) library(plater) data &lt;- read_plates( file = test_data, # full path to the .csv file well_ids_column = &quot;Wells&quot;, # name to give column of well IDs (optional) sep = &quot;,&quot; # separator used in the csv file (optional) ) str(data) head(data) gganimate I’ve been exploring the gganimate package, which allows me to create time-based plots for my data. Specifically, I’m interested in visualizing how long it takes for trypsin to break down all the proteins in my sample, given varying concentrations of trypsin. This package transforms static line graphs into dynamic animations, showing changes over time in a clear and engaging way. # install.packages(&quot;gifski&quot;) # install.packages(&quot;av&quot;) # install.packages(&quot;magick&quot;) library(readxl) library(ggplot2) library(gridExtra) library(dplyr) library(gganimate) # Data inlezen tryp_cas_alg &lt;- read_excel(&quot;~/stagedocumenten/20241028_CasFITC_soja_alg.xlsx&quot;, sheet = &quot;alg_tryp&quot;) # Functie om grafieken te genereren met optionele verticale stippellijn en label plot_function_alg &lt;- function(data, title_text) { p &lt;- ggplot(data, aes(x = as.numeric(incubatietijd_min), y = gemiddelde_extinctie_meting, color = factor(concentratie_peptones), group = factor(concentratie_peptones), linetype = factor(concentratie_peptones))) + geom_line() + geom_point() + scale_y_log10(expand = c(0.1, 0)) + scale_x_continuous(breaks = c(scales::pretty_breaks()(range(as.numeric(data$incubatietijd_min))), 35), expand = c(0.1, 0)) + labs(title = title_text, x = &quot;Incubatietijd (minuten)&quot;, y = &quot;Gemiddelde extinctie (log)&quot;, color = &quot;Concentratie soya (mg/ml)&quot;, linetype = &quot;Concentratie soya (mg/ml)&quot;) + theme_minimal() + theme(plot.margin = unit(c(1, 1, 1, 1), &quot;cm&quot;)) return(p) } # Geanimeerde grafiek maken animated_plot &lt;- plot_function_alg(tryp_cas_alg, &quot;Gemiddelde gemeten extinctie caseïne-FITC over tijd (log)&quot;) + transition_reveal(as.numeric(incubatietijd_min)) # Geanimeerde grafiek maken met gekozen rendering-engine animated_plot &lt;- plot_function_alg(tryp_cas_alg, &quot;Gemiddelde gemeten extinctie caseïne-FITC over tijd (log)&quot;) + transition_reveal(as.numeric(incubatietijd_min)) # save as gif anim_save(&quot;animated_plot.gif&quot;, animated_plot) 4.1 4.2 qPCR References vergeet niet de volgorde aan te passsen!!!!! [^1] Hughes, S. (2024, October 25). Getting started with plater. https://cran.r-project.org/web/packages/plater/vignettes/plater-basics.html 1 A grammar of animated graphics. (n.d.). https://gganimate.com/ Deepika, D., &amp; Kumar, V. (2023). The role of “Physiologically Based Pharmacokinetic Model (PBPK)” New Approach Methodology (NAM) in Pharmaceuticals and Environmental Chemical Risk assessment. International Journal of Environmental Research and Public Health, 20(4), 3473. https://doi.org/10.3390/ijerph20043473↩︎ "],["sql.html", "5 SQL", " 5 SQL # Load required libraries library(tidyr) library(dplyr) library(stringr) library(DBI) library(RPostgres) library(readr) library(dslabs) library(ggplot2) # Load in data flu_data &lt;- read_csv(&quot;~/Rachelle/flu_data.csv&quot;, skip = 11) dengue_data &lt;- read_csv(&quot;~/Rachelle/dengue_data.csv&quot;, skip = 11) gapminder_data &lt;- gapminder # Make data tidy flu_tidy &lt;- pivot_longer(data = flu_data, cols = c(2:30), names_to = &quot;Country&quot;, values_to = &quot;Value&quot;) flu_tidy &lt;- flu_tidy %&gt;% mutate(year = str_sub(Date, 1, 4)) %&gt;% select(-Date) dengue_tidy &lt;- pivot_longer(data = dengue_data, cols = c(2:11), names_to = &quot;Country&quot;, values_to = &quot;Value&quot;) dengue_tidy &lt;- dengue_tidy %&gt;% mutate(year = str_sub(Date, 1, 4)) %&gt;% select(-Date) gapminder_data &lt;- as_tibble(gapminder_data) gapminder_data &lt;- gapminder_data %&gt;% rename(Year = year, Country = country) %&gt;% mutate(Year = as.character(Year)) # Convert Year to character # Save dataframes write.csv(flu_tidy, &quot;flu_tidy.csv&quot;) write.csv(dengue_tidy, &quot;dengue_tidy.csv&quot;) write.csv(gapminder_data, &quot;gapminder_tidy.csv&quot;) saveRDS(flu_tidy, &quot;flu_tidy.rds&quot;) saveRDS(dengue_tidy, &quot;dengue_tidy.rds&quot;) saveRDS(gapminder_data, &quot;gapminder_tidy.rds&quot;) # Connect to database in PostgreSQL con &lt;- dbConnect(RPostgres::Postgres(), dbname = &quot;workflowsdb&quot;, host=&quot;localhost&quot;, port=&quot;5432&quot;, user=&quot;postgres&quot;, password=&quot;password&quot;) dbWriteTable(con, &quot;gapminder&quot;, gapminder_data) dbWriteTable(con, &quot;flu&quot;, flu_tidy) dbWriteTable(con, &quot;dengue&quot;, dengue_tidy) # Inspect contents of the tables knitr::include_graphics(&quot;C:\\\\Users\\\\rache\\\\OneDrive\\\\Documenten\\\\Schermafbeelding 2024-08-18 230338.png&quot;) knitr::include_graphics(&quot;C:\\\\Users\\\\rache\\\\OneDrive\\\\Documenten\\\\Schermafbeelding 2024-08-18 230429.png&quot;) knitr::include_graphics(&quot;C:\\\\Users\\\\rache\\\\OneDrive\\\\Documenten\\\\Schermafbeelding 2024-08-18 230509.png&quot;) # Join the tables together flu_tidy &lt;- flu_tidy %&gt;% mutate(year = as.character(year)) dengue_tidy &lt;- dengue_tidy %&gt;% mutate(year = as.character(year)) flu_dengue &lt;- full_join(flu_tidy, dengue_tidy, by = c(&quot;Country&quot;, &quot;year&quot;), suffix = c(&quot;_flu&quot;, &quot;_dengue&quot;)) # Rename &#39;year&#39; to &#39;Year&#39; in flu_dengue for consistency with gapminder_data flu_dengue &lt;- flu_dengue %&gt;% rename(Year = year) # Join with gapminder flu_dengue_gapminder &lt;- inner_join(flu_dengue, gapminder_data, by = c(&quot;Country&quot;, &quot;Year&quot;)) # Check the resulting dataframe print(flu_dengue_gapminder) ## # A tibble: 155,161 × 11 ## Country Value_flu Year Value_dengue infant_mortality life_expectancy ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Argentina NA 2002 NA 17.1 74.3 ## 2 Australia NA 2002 NA 5 80.3 ## 3 Austria NA 2002 NA 4.4 78.8 ## 4 Belgium NA 2002 NA 4.4 78.2 ## 5 Bolivia NA 2002 0.101 53.7 68.7 ## 6 Brazil 174 2002 0.073 24.3 71.4 ## 7 Bulgaria NA 2002 NA 16.3 72.1 ## 8 Canada NA 2002 NA 5.3 79.6 ## 9 Chile NA 2002 NA 8.3 77.7 ## 10 France NA 2002 NA 4.2 79.4 ## # ℹ 155,151 more rows ## # ℹ 5 more variables: fertility &lt;dbl&gt;, population &lt;dbl&gt;, gdp &lt;dbl&gt;, ## # continent &lt;fct&gt;, region &lt;fct&gt; # Boxplot dengue cases per year in Brazil dengue_Brazil &lt;- flu_dengue_gapminder %&gt;% select(Year, Country, Value_dengue) %&gt;% filter(Country == &quot;Brazil&quot;, !is.na(Value_dengue)) dengue_sum &lt;- dengue_Brazil %&gt;% group_by(Year) %&gt;% summarise(mean = mean(Value_dengue, na.rm = TRUE), stedv = sd(Value_dengue, na.rm= TRUE)) ggplot(dengue_sum, aes(x = as.factor(Year), y = mean)) + geom_point(color = &quot;pink&quot;) + labs(title = &quot;Dengue Cases in Brazil (Per Year)&quot;, x = &quot;Year&quot;, y = &quot;Average Number of Cases&quot;) + theme_minimal() # Barchart of dengue cases per year denguebar_plot &lt;- ggplot(dengue_sum, aes(x = as.factor(Year), y = mean)) + geom_col(fill = &quot;lightpink&quot;, color = &quot;grey&quot;) + labs(title = &quot;Dengue cases Brazil (in years)&quot;, x = &quot;Year&quot;, y = &quot;Average cases of dengue&quot;) + theme_minimal() denguebar_plot "],["datetime-r-package.html", "6 DateTime R Package Introduction Installation Fuctions of the package", " 6 DateTime R Package Introduction This is a user guide for the DateTime package, which allows you to perform operations or calculations with date and time. See this guide for explanations and examples of the functions in this package. Installation To use the DateTime package, use the code below in your console. # install packages &quot;usethis&quot; and &quot;devtools&quot; if they are not already installed library(usethis) library(devtools) # Load the DateTime package in library(DateTime) Fuctions of the package The package contains 4 functions which are related to date and time. date_difference() add_time() is_same_day() is_dutch_holiday() Calculating date difference The date_difference() function allows you to calculate the difference between two dates. The function uses various time units such as seconds, minutes, hours, days, weeks, months, and years. # Load the DateTime package library(DateTime) # Calculate the difference between two dates in days date_difference(&quot;2024-05-21&quot;, &quot;2024-05-22&quot;, units = &quot;days&quot;) ## Time difference of 1 days # Calculate the difference between two dates in weeks date_difference(&quot;2024-05-21&quot;, &quot;2024-06-21&quot;, units = &quot;weeks&quot;) ## Time difference of 4.428571 weeks # Calculate the difference between two dates in years date_difference(&quot;2024-05-21&quot;, &quot;2025-05-22&quot;, units = &quot;years&quot;) ## [1] &quot;Time difference of 1.00205338809035 years&quot; Add time to a date The add_time() function adds a certain amount of time to the filled in date. # Add 1 hour add_time(&quot;2024-05-21 08:00:00&quot;, 1, &quot;hours&quot;) ## [1] &quot;2024-05-21 09:00:00 CEST&quot; # Add 2 weeks add_time(&quot;2024-07-22 07:00:00&quot;, 2, &quot;weeks&quot;) ## [1] &quot;2024-08-05 07:00:00 CEST&quot; # Add 54 seconds add_time(&quot;2024-05-21 08:00:00&quot;, 54, &quot;seconds&quot;) ## [1] &quot;2024-05-21 08:00:54 CEST&quot; Check if two dates are on the same day The is_same_day() function checks whether two dates fall on the same weekday. If so, it returns “TRUE” and gives the name of the weekday. If not, it returns “FALSE” and gives you the two different weekday names. # Check if the 21st of May 2024 falls on the same day as 21st of May 2024. is_same_day(&quot;2024-05-21&quot;, &quot;2024-05-21&quot;) ## $same_day ## [1] TRUE ## ## $day_of_week ## [1] &quot;dinsdag&quot; # Check if the 4th of May 2024 falls on the same day as the 2nd of February 2024 is_same_day(&quot;2024-05-04&quot;, &quot;2024-02-02&quot;) ## $same_day ## [1] FALSE ## ## $day_of_week_1 ## [1] &quot;zaterdag&quot; ## ## $day_of_week_2 ## [1] &quot;vrijdag&quot; Check for Dutch holidays The is_dutch_holiday() function checks if the given date, is also a (legal) Dutch holiday. These holidays are: New Year’s Day Goede Vrijdag / Good Friday Easter Second Easter Day King’s Day Liberation Day (every 5 years) Ascension Day Pentecost Second Pentecost Christmas Day Second Christmas Day is_dutch_holiday(&quot;2024-01-01&quot;) ## [1] TRUE is_dutch_holiday(&quot;2024-08-12&quot;) ## [1] FALSE "],["projecticum-ner.html", "7 Projecticum NER Introduction Physiologically Based Pharmacokinetic models Prodigy Named Entity Recognition models References", " 7 Projecticum NER Introduction For the Data science For Biology course I’m working on a project to help develop Physiologically Based Kinetics (PBK) models, which are used to simulate how chemicals are metabolized in the human body. Building these models is a challenging process that requires collecting a lot of data, like chemical concentrations, tissue properties, and toxicokinetic profiles. This can be time-consuming, error-prone, and difficult to reproduce. My role in the project is to train a small Named Entity Recognition (NER) model that can automatically identify and extract specific details from the methods sections of scientific articles, such as cell culture conditions and incubation times. I’ll be training the model with the use of Python, and my first step is to get familiar with the annotation tool Prodigy and set up a prototype of the model. Physiologically Based Pharmacokinetic models Physiologically Based Pharmacokinetic (PBPK) models are mathematical models encompassing multiple compartments with physiology, anatomy, biochemical and physicochemical parameters for describing ADME (absorption, distribution, metabolism and excretion) of xenobiotics and their metabolites. These models vary from empirical, semi-mechanistic to compartmental models based on the complexity of the problem. The major challenge with empirical or semi-mechanistic models is their difficulty with interpreting questions such as “How to predict concentration–time profile of compound in target organ” or “How to accurately predict the exact dosing while extrapolating from animal to human”. This led to the development of compartmental models, which are close to human anatomy and physiology. Currently, these models are widely acknowledged in the field of pharmaceutical and environmental science for the prediction of PK behavior of xenobiotics (drug/chemical) with respect to dose, route and species [^1]. Prodigy Machine learning systems are built from both code and data. It’s easy to reuse the code but hard to reuse the data, so building AI mostly means doing annotation. Prodigy addresses the big remaining problem: annotation and training. The typical approach to annotation forces projects into an uncomfortable waterfall process. The experiments can’t begin until the first batch of annotations are complete, but the annotation team can’t start until they receive the annotation manuals. To produce the annotation manuals, you need to know what statistical models will be required for the features you’re trying to build. Machine learning is an inherently uncertain technology, but the waterfall annotation process relies on accurate upfront planning. The net result is a lot of wasted effort. Prodigy solves this problem by letting data scientists conduct their own annotations, for rapid prototyping Most annotation tools avoid making any suggestions to the user, to avoid biasing the annotations. Prodigy takes the opposite approach: ask the user as little as possible, and try to guess the rest. Prodigy puts the model in the loop, so that it can actively participate in the training process and learns as you go. The model uses what it already knows to figure out what to ask you next. As you answer the questions, the model is updated, influencing which examples it asks you about next. In order to take full advantage of this strategy, Prodigy is provided as a Python library and command line utility, with a flexible web application 2. Named Entity Recognition models Named Entity Recognition (NER) is a critical component of Natural Language Processing (NLP) that involves identifying and classifying named entities in text into predefined categories such as people, organizations, locations, dates, and more. spaCy, a robust NLP library in Python, offers advanced tools for NER, providing a user-friendly API and powerful models. Named Entity Recognition is a sub-task of information extraction that aims to locate and classify entities within text. These entities are categorized into various predefined classes such as: NER is pivotal for tasks like information retrieval, question answering, and text summarization. It helps in structuring unstructured data, making it easier to analyze and use in applications. spaCy is an open-source NLP library designed for efficient and productive development. It supports tokenization, part-of-speech tagging, dependency parsing, and NER. spaCy’s models are pre-trained on large datasets, which makes it an excellent choice for building robust NLP applications 3. References Deepika, D., &amp; Kumar, V. (2023). The role of “Physiologically Based Pharmacokinetic Model (PBPK)” New Approach Methodology (NAM) in Pharmaceuticals and Environmental Chemical Risk assessment. International Journal of Environmental Research and Public Health, 20(4), 3473. https://doi.org/10.3390/ijerph20043473↩︎ Montani, I. (2019, August 22). Getting started with Prodigy: A step-by-step guide. Ines Montani. https://ines.io/blog/prodigy-first-steps↩︎ "],["parameterized-covid-19-report.html", "8 Parameterized COVID-19 report Importing and inspecting Line chart the Netherlands, Belgium and Germany Line chart Romania, Liechtenstein and Italy", " 8 Parameterized COVID-19 report Parameterized reporting is a technique that allows you to generate multiple reports simultaneously. By using parameterized reporting, you can follow the same process to make 3,000 reports as you would to make one report. The technique also makes your work more accurate, as it avoids copy-and-paste errors. In this chapter we’re making a parameterized report of COVID-19 data obtained from the European Center for Disease Control (ECDC). Importing and inspecting Line chart the Netherlands, Belgium and Germany Using the ECDC COVID-19 data, there is a visual representation of COVID-19 cases and deaths in selected countries and years. The graphs display the number of cases and deaths per date. By utilizing parameterization in the R code with params$, this report can be easily tailored to specific interests without needing to modify the underlying code. Figure 8.1: Line chart of the COVID-19 data from the Netherlands, Belgium and Germany, with the date in years and month on t x-axis, and the amount of cases on the y-axis. de datum in jaar en maand op de x-as staat, de aantal cases op de y-as. Figure 8.2: Line chart of the COVID-19 data from the Netherlands, Belgium and Germany, with the date in years and month on t x-axis, and the amount of cases on the y-axis. de datum in jaar en maand op de x-as staat, de aantal cases op de y-as. Line chart Romania, Liechtenstein and Italy To verify that the parameterization is working correctly, you can adjust the values in the parameter list. In this example, the countries Romania, Norway, and Italy are used, along with the year 2022 Figure 8.3: Line chart of COVID-19 data, with the date in year and month on the x-axis, the number of cases on the y-axis. Different colors represent the selected countries Romania, Liechtenstein, and Italy. Figure 8.4: Line chart of COVID-19 data, with the date in year and month on the x-axis, the number of cases on the y-axis. Different colors represent the selected countries Romania, Liechtenstein, and Italy. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
